## Compute > GPU Instance > 개요

GPU는 고성능 컴퓨팅, 딥 러닝 트레이닝 및 추론, 머신 러닝, 데이터 분석, 그래픽 등 다양한 워크로드의 작업 속도를 향상시킵니다.
GPU 인스턴스는 인스턴스에 GPU(Graphics Processing Unit)가 추가 구성된 가상서버입니다.

여러 개의 GPU를 선택하여 사용 할수 있습니다.


## 기능

* AI 트레이닝
* AI 추론
* 고성능 컴퓨팅
* Deep learning
* Machine learning

## 제공 GPU 제원

### NVIDIA V100

| NVIDIA V100 for NVLink | |
| ----------------------------- | :----------------------------------: |
| GPU  Architecture             |             NVIDIA Volta             |
| NVIDIA Tensor Cores           |                 640                  |
| NVIDIA CUDA Cores             |                 5120                 |
| DOUBLE-PRECISION Performance  |            7.8 teraFLOPS             |
| SINGLE-PRECISION  Performance |            15.7 teraFLOPS            |
| DEEP LEARNING Performance     |            125 teraFLOPS             |
| GPU Memory                    |              32GB HBM2               |
| Memory Bandwidth              |              900GB/sec               |
| Interconnect Bandwidth        |              300GB/sec               |
| System Interface              |            NVIDIA NVLink             |
| Max Power Comsumption         |                300 W                 |
| Compute APIs                  | CUDA, DirectCompute, OpenCL, OpenACC |


### NVIDIA T4

| NVIDIA  T4                               |                             |
| ---------------------------------------- | :---------------------------: |
| GPU Architecture                         | NVIDIA Turing               |
| NVIDIA Tensor Cores                      | 320                         |
| NVIDIA CUDA Cores                        | 2560                        |
| SINGLE-PRECISION  Performance            | 8.1 teraFLOPS               |
| Mixed-Precision  (FP16/FP32) Performance | 65 teraFLOPS                |
| INT8                                     | 130 teraFLOPS               |
| INT8                                     | 260 teraFLOPS               |
| GPU Memory                               | 16GB GDDR6                  |
| Memory Bandwidth                         | 300GB/sec                   |
| Interconnect Bandwidth                   | 32GB/sec                    |
| System Interface                         | x16 PCIe Gen3               |
| Max Power Comsumption                    | 70 W                        |
| Compute APIs                             | CUDA, NVIDIA TensorRT, ONNX |
