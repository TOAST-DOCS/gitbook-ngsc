
## Compute > GPU Instance > 개요

GPU 인스턴스는 인스턴스에 GPU(Graphics Processing Unit)가 추가 구성된 가상서버입니다.
과학적 발견부터 딥러닝에 이르는 다양한 분야에서 사용합니다.

GPU 수량 1개 또는 2개를 선택하여 GPU를 사용할 수 있습니다.

## 기능

* AI 트레이닝
* AI 추론
* 고성능 컴퓨팅

## 제공 GPU 제원

### NVLINK용 NVIDIA TESLA V100

딥 러닝을 위한 궁극의 성능

| Tesla V100 for NVLink |  |
| --- | :---: |
| GPU Architecture | NVIDIA Volta |
| NVIDIA Tensor Cores | 640 |
| NVIDIA CUDA Cores | 5120 |
| Double-Precision Performance | 7.8 TFLOPS |
| Single-Precision Performance | 15.7 TFLOPS |
| Tensor Performance | 125 TFLOPS |
| GPU Memory | 32GB |
| Memory Bandwidth | 900GB/sec |
| ECC | Yes |
| Interconnect Bandwidth | 300GB/sec |
| System Interface | NVIDIA NVLink |
| Form Factor | SXM2 |
| Max Power Comsumption | 300 WATTS |
| Thermal Solution | Passive |
| Compute APIs | CUDA, DirectCompute, OpenCL ™ ,OpenACC |
